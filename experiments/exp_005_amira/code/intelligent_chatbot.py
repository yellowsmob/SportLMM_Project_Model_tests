# intelligent_chatbot.py
"""
Intelligent Equestrian Chatbot - Main Orchestrator
Updated for new knowledge graph structure (no named graphs)
"""

import sys
from graphdb_client import GraphDBClient
from intelligent_sparql_generator import IntelligentSPARQLGenerator
from llm_client import FrenchLLMClient
from context_builder import ContextBuilder
from config import GRAPHDB_ENDPOINT, VERBOSE, SHOW_SPARQL, SHOW_CONTEXT


class IntelligentEquestrianChatbot:
    """
    Main chatbot orchestrating the complete GraphRAG pipeline
    Updated for new ontology structure
    """
    
    def __init__(
        self,
        graphdb_endpoint: str = GRAPHDB_ENDPOINT,
        language: str = "fr"
    ):
        """
        Initialize the chatbot
        
        Args:
            graphdb_endpoint: GraphDB SPARQL endpoint
            language: Response language (fr/en)
        """
        print("Initialisation du Chatbot √âquestre Intelligent...")
        print(f"   Repository: {graphdb_endpoint.split('/')[-1]}")
        print(f"   Langue: {language.upper()}")
        print("   LLM: Local (LM Studio)")
        
        self.language = language
        
        # Initialize all components
        try:
            self.graphdb = GraphDBClient(graphdb_endpoint)
            self.llm = FrenchLLMClient(use_local=True)
            self.sparql_generator = IntelligentSPARQLGenerator(self.llm)
            self.context_builder = ContextBuilder()
            print("Chatbot initialis√©!\n")
        except Exception as e:
            print(f"Erreur lors de l'initialisation: {e}")
            raise
    
    def answer_question(self, question: str, verbose: bool = VERBOSE) -> dict:
        """
        Answer a question about horses
        
        Args:
            question: User's question in natural language
            verbose: Show detailed steps
            
        Returns:
            Dictionary with answer and metadata
        """
        if verbose:
            print(f"\n{'='*80}")
            print(f"QUESTION: {question}")
            print(f"{'='*80}\n")
        
        # ====================================================================
        # STEP 1: Generate SPARQL query using LLM
        # ====================================================================
        if verbose:
            print("√âTAPE 1: G√©n√©ration de la requ√™te SPARQL...")
        
        try:
            query_result = self.sparql_generator.generate_sparql(question, self.language)
            sparql_query = query_result["sparql_query"]
            entities_used = query_result["entities_used"]
            relations_used = query_result["relations_used"]
            explanation = query_result["explanation"]
            
            if verbose:
                print("Requ√™te g√©n√©r√©e!\n")
                print(f"Entit√©s utilis√©es: {', '.join(entities_used) if entities_used else 'N/A'}")
                print(f"Relations utilis√©es: {', '.join(relations_used) if relations_used else 'N/A'}")
                print(f"Explication: {explanation}\n")
                
                if SHOW_SPARQL:
                    print("Requ√™te SPARQL:")
                    print("-" * 80)
                    for line in sparql_query.split('\n'):
                        print(f"  {line}")
                    print("-" * 80)
                    print()
        
        except Exception as e:
            error_msg = f"Erreur lors de la g√©n√©ration SPARQL: {str(e)}"
            print(f"{error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "question": question
            }
        
        # ====================================================================
        # STEP 2: Execute SPARQL on GraphDB
        # ====================================================================
        if verbose:
            print(" √âTAPE 2: Ex√©cution de la requ√™te sur GraphDB...")
        
        try:
            results = self.graphdb.query(sparql_query)
            
            if not results or 'results' not in results:
                if verbose:
                    print(" Aucun r√©sultat retourn√© par GraphDB\n")
                return {
                    "success": False,
                    "error": "Pas de r√©sultats de GraphDB",
                    "question": question,
                    "sparql_query": sparql_query
                }
            
            bindings = results['results']['bindings']
            results_count = len(bindings)
            
            if verbose:
                print(f"{results_count} r√©sultat(s) trouv√©(s)!\n")
        
        except Exception as e:
            error_msg = f"Erreur GraphDB: {str(e)}"
            print(f"{error_msg}")
            
            # Check if it's a SPARQL syntax error
            if "400" in str(e) or "Bad Request" in str(e):
                print("\nSuggestions:")
                print("   - V√©rifiez que la requ√™te SPARQL est syntaxiquement correcte")
                print("   - V√©rifiez que le namespace correspond √† celui de GraphDB")
                print("   - Testez la requ√™te manuellement dans GraphDB web interface")
            
            return {
                "success": False,
                "error": error_msg,
                "question": question,
                "sparql_query": sparql_query
            }
        
        # ====================================================================
        # STEP 3: Build context from results
        # ====================================================================
        if verbose:
            print(" √âTAPE 3: Construction du contexte...")
        
        try:
            context = self.context_builder.format_results(bindings, explanation)
            
            if verbose:
                print(f" Contexte cr√©√© ({len(context)} caract√®res)\n")
                
                if SHOW_CONTEXT and results_count > 0:
                    print(" Aper√ßu du contexte:")
                    print("-" * 80)
                    # Show first 500 chars
                    preview = context[:500]
                    print(preview)
                    if len(context) > 500:
                        print("...")
                    print("-" * 80)
                    print()
        
        except Exception as e:
            error_msg = f"Erreur construction contexte: {str(e)}"
            print(f"{error_msg}")
            # Use raw bindings as fallback
            context = str(bindings)
        
        # ====================================================================
        # STEP 4: Generate natural language answer using LLM
        # ====================================================================
        if verbose:
            print("√âTAPE 4: G√©n√©ration de la r√©ponse en langage naturel...")
        
        try:
            answer = self._generate_answer(question, context, results_count, bindings)
            
            if verbose:
                print("R√©ponse g√©n√©r√©e!\n")
        
        except Exception as e:
            error_msg = f"Erreur g√©n√©ration r√©ponse: {str(e)}"
            print(f"{error_msg}")
            # Fallback: describe raw results
            if results_count > 0:
                answer = f"J'ai trouv√© {results_count} r√©sultat(s), mais je n'ai pas pu g√©n√©rer une r√©ponse naturelle. Voici les donn√©es brutes: {context[:200]}..."
            else:
                answer = "Je n'ai pas trouv√© de r√©sultats pour cette question."
        
        # ====================================================================
        # STEP 5: Display final answer
        # ====================================================================
        if verbose:
            print("R√âPONSE FINALE:")
            print("=" * 80)
            print(answer)
            print("=" * 80)
            print()
        
        return {
            "success": True,
            "question": question,
            "sparql_query": sparql_query,
            "entities_used": entities_used,
            "relations_used": relations_used,
            "explanation": explanation,
            "results_count": results_count,
            "context": context,
            "answer": answer,
            "raw_results": results
        }
    
    def _generate_answer(self, question: str, context: str, results_count: int, bindings: list) -> str:
        """
        Generate natural language answer from context
        
        Args:
            question: Original question
            context: Formatted context from SPARQL results
            results_count: Number of results found
            bindings: Raw SPARQL bindings
            
        Returns:
            Natural language answer in French
        """
        
        # System prompt for answer generation
        system_prompt = """Tu es un assistant expert en donn√©es √©questres.
Tu r√©ponds aux questions en te basant UNIQUEMENT sur le contexte fourni par le graphe de connaissances.
Tu r√©ponds en fran√ßais, de mani√®re claire, pr√©cise et naturelle.
Tu structures tes r√©ponses de fa√ßon informative sans √™tre trop verbeux.
Si l'information n'est pas dans le contexte, tu le dis clairement.
Ne jamais inventer d'informations."""
        
        # Build user prompt
        if results_count == 0:
            user_prompt = f"""Question: {question}

Contexte: Aucune donn√©e trouv√©e dans le graphe de connaissances.

R√©ponds poliment que tu n'as pas trouv√© d'informations pour r√©pondre √† cette question.
Sugg√®re que les donn√©es recherch√©es n'existent peut-√™tre pas encore dans la base."""
        else:
            user_prompt = f"""Question: {question}

Contexte du graphe de connaissances ({results_count} r√©sultats trouv√©s):
{context}

R√©ponds √† la question en te basant uniquement sur ce contexte.
Sois pr√©cis, informatif et naturel. Structure ta r√©ponse de mani√®re claire."""
        
        # Generate answer
        answer = self.llm.generate(user_prompt, system_prompt)
        
        return answer
    
    def chat(self):
        """Interactive chat mode"""
        
        print("\n" + "="*80)
        print("üê¥ CHATBOT √âQUESTRE INTELLIGENT - MODE INTERACTIF")
        print("="*80)
        print("\nPosez vos questions sur:")
        print("  ‚Ä¢ Les chevaux (Dakota)")
        print("  ‚Ä¢ Les entra√Ænements et leur intensit√©")
        print("  ‚Ä¢ Les √©v√©nements sportifs (ShowJumping, Dressage, Cross)")
        print("  ‚Ä¢ Les relations entre chevaux, entra√Ænements et comp√©titions")
        print("\nExemples de questions:")
        print("  - Quels sont tous les chevaux?")
        print("  - Quel cheval participe √† quels entra√Ænements?")
        print("  - Quels entra√Ænements ont une haute intensit√©?")
        print("  - Quelle est la fr√©quence d'entra√Ænement?")
        print("  - Quels √©v√©nements sont pr√©vus?")
        print("\nCommandes:")
        print("  ‚Ä¢ 'quit', 'exit', 'quitter' pour terminer")
        print("  ‚Ä¢ 'help' pour voir les exemples")
        print("="*80)
        
        while True:
            try:
                question = input("\n Votre question: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'quitter', 'bye', 'au revoir']:
                    print("\n Au revoir!")
                    break
                
                if question.lower() in ['help', 'aide', '?']:
                    print("\nExemples de questions:")
                    print("  1. Quels sont tous les chevaux?")
                    print("  2. Quel cheval participe √† quels entra√Ænements?")
                    print("  3. Quels entra√Ænements ont une intensit√© √©lev√©e?")
                    print("  4. Quelle est la fr√©quence des entra√Ænements?")
                    print("  5. Quels √©v√©nements sportifs existent?")
                    print("  6. Quels entra√Ænements d√©pendent de quel √©v√©nement?")
                    continue
                
                # Answer the question
                self.answer_question(question, verbose=True)
                
            except KeyboardInterrupt:
                print("\n\nAu revoir!")
                break
            except Exception as e:
                print(f"\nErreur: {e}")
                import traceback
                traceback.print_exc()


# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Chatbot √âquestre Intelligent',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python intelligent_chatbot.py
      ‚Üí Mode interactif
  
  python intelligent_chatbot.py --question "Quels sont tous les chevaux?"
      ‚Üí Question unique avec affichage d√©taill√©
  
  python intelligent_chatbot.py --question "Quelle est la fr√©quence?" --quiet
      ‚Üí Question unique en mode silencieux
        """
    )
    
    parser.add_argument(
        '--question',
        type=str,
        help='Poser une seule question (au lieu du mode interactif)'
    )
    
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='Mode silencieux (pas de d√©tails, juste la r√©ponse)'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Mode debug (affiche la r√©ponse brute du LLM)'
    )
    
    args = parser.parse_args()
    
    try:
        # Create chatbot
        chatbot = IntelligentEquestrianChatbot()
        
        # Single question or interactive mode
        if args.question:
            verbose = not args.quiet
            result = chatbot.answer_question(args.question, verbose=verbose)
            
            # In quiet mode, just print the answer
            if args.quiet and result.get('success'):
                print(result['answer'])
            elif not result.get('success'):
                print(f"Erreur: {result.get('error', 'Unknown error')}")
                sys.exit(1)
        else:
            # Interactive chat mode
            chatbot.chat()
    
    except KeyboardInterrupt:
        print("\n\nAu revoir!")
        sys.exit(0)
    except Exception as e:
        print(f"\nErreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
